\documentclass[12pt]{article}
\usepackage[paper=letterpaper,margin=1.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{newtxtext, newtxmath}
\usepackage{enumitem}
\usepackage{titling}
\usepackage{svg}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{float}
\usepackage{nicefrac}
\usepackage{multirow}
\usepackage[most]{tcolorbox}
\usepackage[colorlinks=true]{hyperref}

\setlength{\droptitle}{-6em}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{bg}{rgb}{1,0.96,0.9}

\lstdefinestyle{mystyle}{
  commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily\footnotesize,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2
}

% \tcbset{enlarge left by=-0.8cm,left=1.2cm,enlarge right by=-2cm,right=0.8cm}

\lstset{
  style=mystyle,
  inputencoding=utf8,
  extendedchars=true,
}

\newcommand{\question}[1]{\begin{tcolorbox}[enhanced jigsaw,colback=bg,boxrule=0pt,arc=1pt,halign=center] #1 \end{tcolorbox}}

\begin{document}

\begin{enumerate}[leftmargin=\labelsep]
  \question {
  \item Considering the following two-dimensional measurements:

        \begin{table}[H]
          \centering
          \begin{tabular}{c|c|c}
                  & $y_1$ & $y_2$ \\ \hline
            $x_1$ & -2    & 2     \\
            $x_2$ & -1    & 3     \\
            $x_3$ & 0     & 1     \\
            $x_4$ & -2    & 1
          \end{tabular}
        \end{table}

        \begin{enumerate}
          \item What are the maximum likelihood parameters of a multivariate Gaussian
                distribution for this data set?
          \item What is the Gaussian's shape? Draw its contour plot.
        \end{enumerate}
        }

        \begin{enumerate}
          \item {}
          \item {}
        \end{enumerate}

        \question {
  \item Consider the following data-set, paired with a query vector $x_{new} = \begin{bmatrix} 1 & 1 & 1 & 1 & 1\end{bmatrix}^T$:

        \begin{table}[H]
          \centering
          \begin{tabular}{c|c|c|c|c|c|c}
                  & $y_1$ & $y_2$ & $y_3$ & $y_4$ & $y_5$ & $z$ \\ \hline
            $x_1$ & 1     & 1     & 0     & 1     & 0     & 1   \\
            $x_2$ & 1     & 1     & 1     & 0     & 0     & 0   \\
            $x_3$ & 0     & 1     & 1     & 1     & 0     & 0   \\
            $x_4$ & 0     & 0     & 0     & 1     & 1     & 0   \\
            $x_5$ & 1     & 0     & 1     & 1     & 1     & 1   \\
            $x_6$ & 0     & 0     & 1     & 0     & 0     & 1   \\
            $x_7$ & 0     & 0     & 0     & 0     & 1     & 1   \\
          \end{tabular}
        \end{table}

        \begin{enumerate}
          \item Using Bayes' rule, without making any assumptions, compute the posterior
                probabilities for the query vector. How is it classified?
          \item What is the problem of working without assumptions?
          \item Compute the class for the same query vector under the naive Bayes assumption?
          \item Consider the presence of missings. Under the same naive Bayes assumption,
                how would you classify the query vector $x_{new} = \begin{bmatrix} 1 & ? & 1 & ? & 1\end{bmatrix}^T$?
        \end{enumerate}
        }

        \begin{enumerate}
          \item {}
          \item {}
          \item {}
          \item {}
        \end{enumerate}

        \question {
  \item Considering the following data set, paired with the query vector $x_{new} = \begin{bmatrix} 100 & 225 \end{bmatrix}^T$:

        \begin{table}[H]
          \centering
          \begin{tabular}{c|c|c|c}
                  & $y_1$ & $y_2$ & z \\ \hline
            $x_1$ & 170   & 160   & 0 \\
            $x_2$ & 80    & 220   & 1 \\
            $x_3$ & 90    & 200   & 1 \\
            $x_4$ & 60    & 160   & 0 \\
            $x_5$ & 50    & 150   & 0 \\
            $x_6$ & 70    & 190   & 1
          \end{tabular}
        \end{table}

        \begin{enumerate}
          \item Compute the most probable class for the query vector assuming that the likelihoods are 2-dimensional Gaussians.
          \item Compute the most probable class for the query vector, under the Naive Bayes assumption,
                using 1-dimensional Gaussians to model the likelihoods.
        \end{enumerate}
        }

        \begin{enumerate}
          \item {}
          \item {}
        \end{enumerate}

        \question {
  \item Assuming training examples with $m$ features and a binary class:

        \begin{enumerate}
          \item How many parameters are needed to estimate, considering boolean features and:
                \begin{enumerate}
                  \item No assumptions regarding the data's distribution.
                  \item Naive Bayes assumption.
                \end{enumerate}
          \item How many parameters are needed to estimate, considering numeric-valued features and:
                \begin{enumerate}
                  \item Multivariate Gaussian assumption.
                  \item Naive Bayes assumption.
                \end{enumerate}
        \end{enumerate}
        }

        \begin{enumerate}
          \item {
                \begin{enumerate}
                  \item {}
                  \item {}
                \end{enumerate}
                }
          \item {
                \begin{enumerate}
                  \item {}
                  \item {}
                \end{enumerate}
                }
        \end{enumerate}

\end{enumerate}

\end{document}