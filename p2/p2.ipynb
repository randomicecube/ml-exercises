{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = np.array([\n",
    "  [\"a\", \"a\", \"a\"],\n",
    "  [\"c\", \"b\", \"c\"],\n",
    "  [\"c\", \"a\", \"c\"],\n",
    "  [\"b\", \"a\", \"a\"],\n",
    "  [\"a\", \"b\", \"c\"],\n",
    "  [\"b\", \"b\", \"c\"],\n",
    "])\n",
    "\n",
    "LABELS = np.array([\n",
    "  [\"+\", \"+\", \"+\", \"-\", \"-\", \"-\"],\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target entropy: 1.0\n",
      "Attribute: y_1\n",
      "Weighted entropy: 0.3333333333333333\n",
      "I(Gain, a0) = 0.667\n",
      "Attribute: y_2\n",
      "Weighted entropy: 0.9182958340544896\n",
      "I(Gain, a1) = 0.082\n",
      "Attribute: y_3\n",
      "Weighted entropy: 1.0\n",
      "I(Gain, a2) = 0.000\n"
     ]
    }
   ],
   "source": [
    "def calc_entropy(labels):\n",
    "  \"\"\"Calculate entropy of a list of labels.\"\"\"\n",
    "  _, counts = np.unique(labels, return_counts=True)\n",
    "  probs = counts / counts.sum()\n",
    "  return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "def calc_info_gain(data, labels, attr, total_entropy):\n",
    "  \"\"\"Calculate information gain of a data set for an attribute.\"\"\"\n",
    "  # Calculate entropy of labels after split\n",
    "  vals, counts = np.unique(data[:, attr], return_counts=True)\n",
    "  probs = counts / counts.sum()\n",
    "  weighted_entropy = np.sum([\n",
    "    probs[i] * calc_entropy(labels[data[:, attr] == vals[i]])\n",
    "    for i in range(len(vals))\n",
    "  ])\n",
    "\n",
    "  print(\"Weighted entropy: {}\".format(weighted_entropy))\n",
    "\n",
    "  # Calculate information gain\n",
    "  return total_entropy - weighted_entropy\n",
    "\n",
    "target_entropy = calc_entropy(LABELS)\n",
    "print(\"Target entropy: {}\".format(target_entropy))\n",
    "\n",
    "# Calculate information gain for each attribute\n",
    "for i in range(SAMPLES.shape[1]):\n",
    "  print(f\"Attribute: y_{i + 1}\")\n",
    "  print(f\"I(Gain, a{i}) = {calc_info_gain(SAMPLES, LABELS, i, target_entropy):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
